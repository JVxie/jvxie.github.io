<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python爬虫学习笔记（一）Scrapy框架实战 | JVxie's Blog</title><meta name="description" content="写在前面 这篇博客来记录学习Python爬虫 主要是为了应付数据可视化这门课程而写，虽然标题有（一），但可能不会有（二）了 毕竟本人不是走这方面路子的（逃  什么是Scrapy  Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取A"><meta name="keywords" content="学习笔记,技术,Python,Scrapy"><meta name="author" content="Jeson Vendetta Xie"><meta name="copyright" content="Jeson Vendetta Xie"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/icon.png"><link rel="canonical" href="http://jvxie.com/spider-learning/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="Python爬虫学习笔记（一）Scrapy框架实战"><meta property="og:url" content="http://jvxie.com/spider-learning/"><meta property="og:site_name" content="JVxie's Blog"><meta property="og:description" content="写在前面 这篇博客来记录学习Python爬虫 主要是为了应付数据可视化这门课程而写，虽然标题有（一），但可能不会有（二）了 毕竟本人不是走这方面路子的（逃  什么是Scrapy  Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取A"><meta property="og:image" content="https://i.loli.net/2020/07/04/sRLU9dIAPOBKM5u.png"><meta property="article:published_time" content="2020-07-03T10:20:57.000Z"><meta property="article:modified_time" content="2020-07-03T18:09:20.231Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'true'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="next" title="Java Swing组件学习笔记" href="http://jvxie.com/Java-Swing-learning/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: false,
  islazyload: true,
  isanchor: false    
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true
  }</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.1.1"><link rel="alternate" href="/atom.xml" title="JVxie's Blog" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/jvxie.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">8</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">23</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">11</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于我</span></a></div></div></div></div><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#写在前面"><span class="toc-number">1.</span> <span class="toc-text"> 写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#什么是scrapy"><span class="toc-number">2.</span> <span class="toc-text"> 什么是Scrapy</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#如何安装"><span class="toc-number">3.</span> <span class="toc-text"> 如何安装</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#开始使用"><span class="toc-number">4.</span> <span class="toc-text"> 开始使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#创建项目"><span class="toc-number">4.1.</span> <span class="toc-text"> 创建项目</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#创建一个爬虫"><span class="toc-number">4.2.</span> <span class="toc-text"> 创建一个爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#运行爬虫"><span class="toc-number">4.3.</span> <span class="toc-text"> 运行爬虫</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实战"><span class="toc-number">5.</span> <span class="toc-text"> 实战</span></a></li></ol></div></div></div><div id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://i.loli.net/2020/07/04/sRLU9dIAPOBKM5u.png)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">JVxie's Blog</a></span><span class="pull-right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于我</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Python爬虫学习笔记（一）Scrapy框架实战</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-07-03 18:20:57"><i class="far fa-calendar-alt fa-fw"></i> 发表于 2020-07-03</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-07-04 02:09:20"><i class="fas fa-history fa-fw"></i> 更新于 2020-07-04</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a><i class="fas fa-angle-right post-meta__separator"></i><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E6%8A%80%E6%9C%AF/%E7%88%AC%E8%99%AB/">爬虫</a><i class="fas fa-angle-right post-meta__separator"></i><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E6%8A%80%E6%9C%AF/%E7%88%AC%E8%99%AB/Python/">Python</a><i class="fas fa-angle-right post-meta__separator"></i><i class="fas fa-inbox fa-fw post-meta__icon"></i><a class="post-meta__categories" href="/categories/%E6%8A%80%E6%9C%AF/%E7%88%AC%E8%99%AB/Python/Scrapy/">Scrapy</a></span></div><div class="meta-secondline"> <span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta__icon"></i><span>字数总计:</span><span class="word-count">1.7k</span><span class="post-meta__separator">|</span><i class="far fa-clock fa-fw post-meta__icon"></i><span>阅读时长: 6 分钟</span></span></div><div class="meta-thirdline"><span class="post-meta-pv-cv"><span class="post-meta__separator">|</span><i class="far fa-eye fa-fw post-meta__icon"></i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="写在前面"><a class="markdownIt-Anchor" href="#写在前面"></a> 写在前面</h1>
<p>这篇博客来记录学习Python爬虫</p>
<p>主要是为了应付数据可视化这门课程而写，虽然标题有（一），但可能不会有（二）了</p>
<p>毕竟本人不是走这方面路子的（逃</p>
<h1 id="什么是scrapy"><a class="markdownIt-Anchor" href="#什么是scrapy"></a> 什么是Scrapy</h1>
<blockquote>
<p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。</p>
<p>其最初是为了 <a href="http://en.wikipedia.org/wiki/Screen_scraping" target="_blank" rel="noopener">页面抓取</a> (更确切来说, <a href="http://en.wikipedia.org/wiki/Web_scraping" target="_blank" rel="noopener">网络抓取</a> )所设计的， 也可以应用在获取API所返回的数据(例如 <a href="http://aws.amazon.com/associates/" target="_blank" rel="noopener">Amazon Associates Web Services</a> ) 或者通用的网络爬虫。</p>
</blockquote>
<p><em>以上内容引用自<a href="https://scrapy-chs.readthedocs.io/zh_CN/latest/intro/overview.html" target="_blank" rel="noopener">初窥Scrapy——Scarpy 0.24.1 文档</a></em></p>
<p>Scrapy的框架如下</p>
<p><img src= "/img/loading_img.gif" data-src="https://i.loli.net/2020/07/04/F3XaJpQMYPEz4SU.jpg" alt="m7T2E2r" /></p>
<ul>
<li>
<p>crapy Engine(引擎): 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。</p>
</li>
<li>
<p>Scheduler(调度器): 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。</p>
</li>
<li>
<p>Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理，</p>
</li>
<li>
<p>Spider（爬虫）：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)，</p>
</li>
<li>
<p>Item Pipeline(管道)：它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方.</p>
</li>
<li>
<p>Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件。</p>
</li>
<li>
<p>Spider Middlewares（Spider中间件）：你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests）</p>
</li>
</ul>
<h1 id="如何安装"><a class="markdownIt-Anchor" href="#如何安装"></a> 如何安装</h1>
<p>首先，确保你的计算机里已经安装好了Python（2.7以上）</p>
<p>先从<a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted" target="_blank" rel="noopener">这里</a>下载对应系统版本的twisted文件（如Twisted-xxx-win_amd64.whl），用pip安装它。（否则安装Scrapy会出错）</p>
<p>接着在终端输入<code>pip install scrapy</code>即可安装成功</p>
<p><em>注：Python3以上的版本可能是pip3</em></p>
<h1 id="开始使用"><a class="markdownIt-Anchor" href="#开始使用"></a> 开始使用</h1>
<p>以下内容以爬取<a href="https://douyu.com" target="_blank" rel="noopener">斗鱼</a>主播为例</p>
<h2 id="创建项目"><a class="markdownIt-Anchor" href="#创建项目"></a> 创建项目</h2>
<p>在你要存放项目的位置开启终端，并键入以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject &lt;project name&gt;</span><br></pre></td></tr></table></figure>
<p>即可在当前目录创建名为<code>&lt;project name&gt;</code>的项目，出现如下图提示即表示创建成功</p>
<p><img src= "/img/loading_img.gif" data-src="https://i.loli.net/2020/07/04/Qkb1FeThv6wgulS.png" alt="2" /></p>
<p>这里<code>&lt;projcet name&gt;</code>取<code>douyu</code>，创建完后会自动生成一个名为<code>douyu</code>的文件夹，目录如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">douyu&#x2F;</span><br><span class="line">    scrapy.cfg</span><br><span class="line">    douyu&#x2F;</span><br><span class="line">        __init__.py</span><br><span class="line">        items.py</span><br><span class="line">        middlewares.py</span><br><span class="line">        pipelines.py</span><br><span class="line">        settings.py</span><br><span class="line">        spiders&#x2F;</span><br><span class="line">            __init__.py</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure>
<ul>
<li><code>scrapy.cfg</code>：项目的配置文件</li>
<li><code>items.py</code>：存放容器的文件</li>
<li><code>middlewares.py</code>：下载中间件和Spider中间件的定义和实现文件</li>
<li><code>pipelines.py</code>：管道的定义和实现文件，用于数据清洗、存储及验证</li>
<li><code>settings.py</code>：项目的设置文件</li>
<li><code>spiders/</code>：存放爬虫代码的目录</li>
</ul>
<h2 id="创建一个爬虫"><a class="markdownIt-Anchor" href="#创建一个爬虫"></a> 创建一个爬虫</h2>
<p>终端进入到项目中的<code>douyu</code>目录，并键入以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider &lt;spider name&gt; &lt;domain&gt;</span><br></pre></td></tr></table></figure>
<p><em>这里的<code>&lt;spider name&gt;</code>指的是爬虫文件的名字，可以自定义，<code>&lt;domain&gt;</code>指的是要爬取的网站</em></p>
<p>即可在<code>spider</code>目录下新建一个爬虫文件，出现如下图提示即代表创建成功</p>
<p><img src= "/img/loading_img.gif" data-src="https://i.loli.net/2020/07/04/VLbRkXHeD73j1Ui.png" alt="3" /></p>
<p>创建好的<code>douyu_spider.py</code>应该长这样</p>
<p><img src= "/img/loading_img.gif" data-src="https://i.loli.net/2020/07/04/FOf6XHagy4wWiU9.png" alt="4" /></p>
<p>其中包含的属性分别代表</p>
<ul>
<li><code>name</code>： 用于区别Spider。 该名字必须是唯一的，您不可以为不同的Spider设定相同的名字。</li>
<li><code>allowed_domains</code>：包含了Sprider爬取的域名，防止爬取到其他域名</li>
<li><code>start_urls</code> ：包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一， 后续的URL则从初始的URL获取到的数据中提取</li>
<li><code>parse()</code> ：将调用的方法，用于处理为每个请求下载的响应。响应参数是的实例 <code>TextResponse</code>它保存页面内容，并有进一步有用的方法来处理它</li>
</ul>
<h2 id="运行爬虫"><a class="markdownIt-Anchor" href="#运行爬虫"></a> 运行爬虫</h2>
<p>终端回到项目的顶级目录，并键入以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl &lt;spider name&gt;</span><br></pre></td></tr></table></figure>
<p><em>注意：这里的<code>spider name</code>指的是爬虫文件里的<code>name</code>，而非爬虫文件名</em></p>
<p>出现如下图的提示信息即代表执行爬虫成功</p>
<p><img src= "/img/loading_img.gif" data-src="https://i.loli.net/2020/07/04/SigalrI4h6FAC5y.png" alt="5" /></p>
<p>这些都只是基础的安装运行，这样的爬虫并无任何作用，接下来要进行更深层的实战</p>
<h1 id="实战"><a class="markdownIt-Anchor" href="#实战"></a> 实战</h1>
<p>这个实战爬取的是斗鱼上颜值主播（绿色健康）的相关信息，如封面、昵称</p>
<p>首先我们需要获取到能够爬取的URL，这里可以用Chrome自带的开发者工具切换到手机端获取</p>
<p><img src= "/img/loading_img.gif" data-src="https://i.loli.net/2020/07/04/bYiv5SIzEt71sGB.gif" alt="6" /></p>
<p>经查看可以发现，一个请求可以获取到8条内容</p>
<p><img src= "/img/loading_img.gif" data-src="https://i.loli.net/2020/07/04/ouw6cNFxgKfY3kd.png" alt="7" /></p>
<p>当然也可以通过抓包的方式获取手机端app的URL，这里不予演示，直接给出地址： <a href="http://capi.douyucdn.cn/api/v1/getVerticalRoom?type=yz&amp;limit=20&amp;offset=" target="_blank" rel="noopener">http://capi.douyucdn.cn/api/v1/getVerticalRoom?type=yz&amp;limit=20&amp;offset=</a></p>
<p>通过接口我们可以发现要爬取的字段名称是<code>nickname</code>和<code>ertical_src</code></p>
<p><img src= "/img/loading_img.gif" data-src="https://i.loli.net/2020/07/04/iSZNIEC1fRd6Q4o.png" alt="8" /></p>
<p>所以要去修改<code>items.py</code>，以得到我们想要的字段</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DouyuItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># 主播昵称</span></span><br><span class="line">    nickname = scrapy.Field()</span><br><span class="line">    <span class="comment"># 封面图片</span></span><br><span class="line">    vertical_src = scrapy.Field()</span><br></pre></td></tr></table></figure>
<p>接下来就是新建一个爬虫文件，取名为<code>douyu_yz</code>，并修改相关内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> douyu.items <span class="keyword">import</span> DouyuItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DouyuYzSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'douyu_yz'</span></span><br><span class="line">    allowed_domains = [<span class="string">'douyu.com'</span>]</span><br><span class="line">    base_url = <span class="string">'http://capi.douyucdn.cn/api/v1/getVerticalRoom?type=yz&amp;limit=20&amp;offset='</span></span><br><span class="line">    offset = <span class="number">0</span></span><br><span class="line">    start_urls = [base_url + str(offset)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># 提取数据，这里获取到的数据是json格式，可以直接转换数据类型</span></span><br><span class="line">        data_list = json.loads(response.body)[<span class="string">'data'</span>]</span><br><span class="line">        <span class="keyword">if</span> len(data_list) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_list:</span><br><span class="line">            item = DouyuItem()</span><br><span class="line">            item[<span class="string">'nickname'</span>] = data[<span class="string">'nickname'</span>].encode(<span class="string">'utf-8'</span>)</span><br><span class="line">            item[<span class="string">'vertical_src'</span>] = data[<span class="string">'vertical_src'</span>]</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line">            </span><br><span class="line">        self.offset += <span class="number">20</span></span><br><span class="line">        url = self.base_url + str(self.offset)</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url, callback=self.parse, dont_filter=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><em>注：这里由于要爬取的信息比较多，所以以变量的方式把URL存成集合，并使用<code>yield</code>关键字回传数据</em></p>
<p>再接着就是编写管道文件了，需要获取到图片文件并进行解码和重命名</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DouyuPipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span><span class="params">(self, item, info)</span>:</span></span><br><span class="line">        image_link = item[<span class="string">'vertical_src'</span>]</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(image_link)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(self, results, item, info)</span>:</span></span><br><span class="line">        path = <span class="string">'/Users/JVxie/Desktop/douyu_yz/'</span></span><br><span class="line">        <span class="keyword">if</span> results[<span class="number">0</span>][<span class="number">0</span>]:</span><br><span class="line">            os.rename(path + results[<span class="number">0</span>][<span class="number">1</span>][<span class="string">'path'</span>], path + str((item[<span class="string">'nickname'</span>]).decode() + <span class="string">".jpg"</span>))</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>到这里，一个基本的爬虫项目已经完成，最后就是在<code>settings.py</code>中增加（修改）我们需要的配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置图片文件路径</span></span><br><span class="line">IMAGES_STORE = <span class="string">'/Users/JVxie/Desktop/douyu_yz'</span></span><br><span class="line"><span class="comment"># 开启管道</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'douyu.pipelines.DouyuPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 关闭robots协议</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>接下来执行<code>scrapy crawl douyu_yz</code>以进行爬取</p>
<p>可能会遇到的问题：</p>
<p><img src= "/img/loading_img.gif" data-src="https://i.loli.net/2020/07/04/fdXg5ikFN3CKL1q.png" alt="9" /></p>
<p>这是由于没有安装<code>pillow</code>库，使用<code>pip</code>安装即可</p>
<p>爬虫执行完成后在自定的目录中就能看到这些主播的封面图片了</p>
<p><img src= "/img/loading_img.gif" data-src="https://i.loli.net/2020/07/04/a2s3pC59g1KPzRH.png" alt="10" /></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Jeson Vendetta Xie</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://jvxie.com/spider-learning/">http://jvxie.com/spider-learning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://jvxie.com" target="_blank">JVxie's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/Scrapy/">Scrapy</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/07/04/sRLU9dIAPOBKM5u.png" data-sites="facebook,twitter,google,weibo,wechat,qq,qzone"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><button class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.png" alt="微信" onclick="window.open('/img/wechat.png')"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/alipay.png" alt="支付宝" onclick="window.open('/img/alipay.png')"/><div class="post-qr-code__desc">支付宝</div></li></ul></div></button></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/Java-Swing-learning/"><img class="next-cover" data-src="https://ae01.alicdn.com/kf/H547144fd2ff74915a5fd9043c70c2be3w.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Java Swing组件学习笔记</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/Java-Swing-learning/" title="Java Swing组件学习笔记"><img class="relatedPosts_cover" data-src="https://ae01.alicdn.com/kf/H547144fd2ff74915a5fd9043c70c2be3w.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-27</div><div class="relatedPosts_title">Java Swing组件学习笔记</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var requestSetting = function (from,set) {
  var from = from
  var setting = set.split(',').filter(function(item){
  return from.indexOf(item) > -1
  });
  setting = setting.length == 0 ? from :setting;
  return setting
}

var guestInfo = requestSetting(['nick','mail','link'],'nick,mail,link')
var requiredFields = requestSetting(['nick','mail'],'nick,mail')

window.valine = new Valine({
  el:'#vcomment',
  appId: 'Fi2L1BRDMHFjLgV2rfPDPnYw-gzGzoHsz',
  appKey: 'UpdA3fdxMEswTW52A79QFrFh',
  placeholder: '来都来了，不说点什么吗？',
  avatar: 'monsterid',
  meta: guestInfo,
  pageSize: '10',
  lang: 'zh-CN',
  recordIP: false,
  serverURLs: '',
  emojiCDN: '',
  emojiMaps: "",
  enableQQ: true,
  requiredFields: requiredFields
});</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2020 By Jeson Vendetta Xie</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="icp"><a href="http://www.beian.miit.gov.cn/" target="_blank" rel="noopener"><img class="icp-icon" src="/img/icp.png"/><span>闽ICP备16020881号-2</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><button id="readmode" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" title="缩小字体"><i class="fas fa-minus"></i></button><button class="translate_chn_to_cht" id="translateLink" title="简繁转换">繁</button><button id="darkmode" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" title="设置"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fas fa-comments"></i></a><button class="close" id="mobile-toc-button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script defer id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><script src="/js/search/local-search.js"></script></body></html>