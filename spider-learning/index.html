<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python爬虫学习笔记（一）Scrapy框架实战 | JVxie's Blog</title><meta name="keywords" content="学习笔记,技术,Python,Scrapy"><meta name="author" content="Jeson Vendetta Xie"><meta name="copyright" content="Jeson Vendetta Xie"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="写在前面 这篇博客来记录学习Python爬虫 主要是为了应付数据可视化这门课程而写，虽然标题有（一），但可能不会有（二）了 毕竟本人不是走这方面路子的（逃  什么是Scrapy  Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取A">
<meta property="og:type" content="article">
<meta property="og:title" content="Python爬虫学习笔记（一）Scrapy框架实战">
<meta property="og:url" content="http://jvxie.com/spider-learning/index.html">
<meta property="og:site_name" content="JVxie&#39;s Blog">
<meta property="og:description" content="写在前面 这篇博客来记录学习Python爬虫 主要是为了应付数据可视化这门课程而写，虽然标题有（一），但可能不会有（二）了 毕竟本人不是走这方面路子的（逃  什么是Scrapy  Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。 其最初是为了 页面抓取 (更确切来说, 网络抓取 )所设计的， 也可以应用在获取A">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2020/07/04/sRLU9dIAPOBKM5u.png">
<meta property="article:published_time" content="2020-07-03T10:20:57.000Z">
<meta property="article:modified_time" content="2020-07-03T18:09:20.231Z">
<meta property="article:author" content="Jeson Vendetta Xie">
<meta property="article:tag" content="学习笔记">
<meta property="article:tag" content="技术">
<meta property="article:tag" content="Python">
<meta property="article:tag" content="Scrapy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/07/04/sRLU9dIAPOBKM5u.png"><link rel="shortcut icon" href="/img/icon.png"><link rel="canonical" href="http://jvxie.com/spider-learning/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2020-07-04 02:09:20'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    })(window)</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="JVxie's Blog" type="application/atom+xml">
</head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/jvxie.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://i.loli.net/2020/07/04/sRLU9dIAPOBKM5u.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">JVxie's Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Python爬虫学习笔记（一）Scrapy框架实战</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-07-03T10:20:57.000Z" title="发表于 2020-07-03 18:20:57">2020-07-03</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-07-03T18:09:20.231Z" title="更新于 2020-07-04 02:09:20">2020-07-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/">技术</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/%E7%88%AC%E8%99%AB/">爬虫</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/%E7%88%AC%E8%99%AB/Python/">Python</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%8A%80%E6%9C%AF/%E7%88%AC%E8%99%AB/Python/Scrapy/">Scrapy</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">1.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>6分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/spider-learning/#post-comment"><span class="waline-comment-count" id="/spider-learning/"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="写在前面"><a class="markdownIt-Anchor" href="#写在前面"></a> 写在前面</h1>
<p>这篇博客来记录学习Python爬虫</p>
<p>主要是为了应付数据可视化这门课程而写，虽然标题有（一），但可能不会有（二）了</p>
<p>毕竟本人不是走这方面路子的（逃</p>
<h1 id="什么是scrapy"><a class="markdownIt-Anchor" href="#什么是scrapy"></a> 什么是Scrapy</h1>
<blockquote>
<p>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。</p>
<p>其最初是为了 <a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Screen_scraping">页面抓取</a> (更确切来说, <a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Web_scraping">网络抓取</a> )所设计的， 也可以应用在获取API所返回的数据(例如 <a target="_blank" rel="noopener" href="http://aws.amazon.com/associates/">Amazon Associates Web Services</a> ) 或者通用的网络爬虫。</p>
</blockquote>
<p><em>以上内容引用自<a target="_blank" rel="noopener" href="https://scrapy-chs.readthedocs.io/zh_CN/latest/intro/overview.html">初窥Scrapy——Scarpy 0.24.1 文档</a></em></p>
<p>Scrapy的框架如下</p>
<p><img src="https://i.loli.net/2020/07/04/F3XaJpQMYPEz4SU.jpg" alt="m7T2E2r" /></p>
<ul>
<li>
<p>crapy Engine(引擎): 负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。</p>
</li>
<li>
<p>Scheduler(调度器): 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。</p>
</li>
<li>
<p>Downloader（下载器）：负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给Spider来处理，</p>
</li>
<li>
<p>Spider（爬虫）：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)，</p>
</li>
<li>
<p>Item Pipeline(管道)：它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方.</p>
</li>
<li>
<p>Downloader Middlewares（下载中间件）：你可以当作是一个可以自定义扩展下载功能的组件。</p>
</li>
<li>
<p>Spider Middlewares（Spider中间件）：你可以理解为是一个可以自定扩展和操作引擎和Spider中间通信的功能组件（比如进入Spider的Responses;和从Spider出去的Requests）</p>
</li>
</ul>
<h1 id="如何安装"><a class="markdownIt-Anchor" href="#如何安装"></a> 如何安装</h1>
<p>首先，确保你的计算机里已经安装好了Python（2.7以上）</p>
<p>先从<a target="_blank" rel="noopener" href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted">这里</a>下载对应系统版本的twisted文件（如Twisted-xxx-win_amd64.whl），用pip安装它。（否则安装Scrapy会出错）</p>
<p>接着在终端输入<code>pip install scrapy</code>即可安装成功</p>
<p><em>注：Python3以上的版本可能是pip3</em></p>
<h1 id="开始使用"><a class="markdownIt-Anchor" href="#开始使用"></a> 开始使用</h1>
<p>以下内容以爬取<a target="_blank" rel="noopener" href="https://douyu.com">斗鱼</a>主播为例</p>
<h2 id="创建项目"><a class="markdownIt-Anchor" href="#创建项目"></a> 创建项目</h2>
<p>在你要存放项目的位置开启终端，并键入以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject &lt;project name&gt;</span><br></pre></td></tr></table></figure>
<p>即可在当前目录创建名为<code>&lt;project name&gt;</code>的项目，出现如下图提示即表示创建成功</p>
<p><img src="https://i.loli.net/2020/07/04/Qkb1FeThv6wgulS.png" alt="2" /></p>
<p>这里<code>&lt;projcet name&gt;</code>取<code>douyu</code>，创建完后会自动生成一个名为<code>douyu</code>的文件夹，目录如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">douyu&#x2F;</span><br><span class="line">    scrapy.cfg</span><br><span class="line">    douyu&#x2F;</span><br><span class="line">        __init__.py</span><br><span class="line">        items.py</span><br><span class="line">        middlewares.py</span><br><span class="line">        pipelines.py</span><br><span class="line">        settings.py</span><br><span class="line">        spiders&#x2F;</span><br><span class="line">            __init__.py</span><br><span class="line">            ...</span><br></pre></td></tr></table></figure>
<ul>
<li><code>scrapy.cfg</code>：项目的配置文件</li>
<li><code>items.py</code>：存放容器的文件</li>
<li><code>middlewares.py</code>：下载中间件和Spider中间件的定义和实现文件</li>
<li><code>pipelines.py</code>：管道的定义和实现文件，用于数据清洗、存储及验证</li>
<li><code>settings.py</code>：项目的设置文件</li>
<li><code>spiders/</code>：存放爬虫代码的目录</li>
</ul>
<h2 id="创建一个爬虫"><a class="markdownIt-Anchor" href="#创建一个爬虫"></a> 创建一个爬虫</h2>
<p>终端进入到项目中的<code>douyu</code>目录，并键入以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider &lt;spider name&gt; &lt;domain&gt;</span><br></pre></td></tr></table></figure>
<p><em>这里的<code>&lt;spider name&gt;</code>指的是爬虫文件的名字，可以自定义，<code>&lt;domain&gt;</code>指的是要爬取的网站</em></p>
<p>即可在<code>spider</code>目录下新建一个爬虫文件，出现如下图提示即代表创建成功</p>
<p><img src="https://i.loli.net/2020/07/04/VLbRkXHeD73j1Ui.png" alt="3" /></p>
<p>创建好的<code>douyu_spider.py</code>应该长这样</p>
<p><img src="https://i.loli.net/2020/07/04/FOf6XHagy4wWiU9.png" alt="4" /></p>
<p>其中包含的属性分别代表</p>
<ul>
<li><code>name</code>： 用于区别Spider。 该名字必须是唯一的，您不可以为不同的Spider设定相同的名字。</li>
<li><code>allowed_domains</code>：包含了Sprider爬取的域名，防止爬取到其他域名</li>
<li><code>start_urls</code> ：包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一， 后续的URL则从初始的URL获取到的数据中提取</li>
<li><code>parse()</code> ：将调用的方法，用于处理为每个请求下载的响应。响应参数是的实例 <code>TextResponse</code>它保存页面内容，并有进一步有用的方法来处理它</li>
</ul>
<h2 id="运行爬虫"><a class="markdownIt-Anchor" href="#运行爬虫"></a> 运行爬虫</h2>
<p>终端回到项目的顶级目录，并键入以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl &lt;spider name&gt;</span><br></pre></td></tr></table></figure>
<p><em>注意：这里的<code>spider name</code>指的是爬虫文件里的<code>name</code>，而非爬虫文件名</em></p>
<p>出现如下图的提示信息即代表执行爬虫成功</p>
<p><img src="https://i.loli.net/2020/07/04/SigalrI4h6FAC5y.png" alt="5" /></p>
<p>这些都只是基础的安装运行，这样的爬虫并无任何作用，接下来要进行更深层的实战</p>
<h1 id="实战"><a class="markdownIt-Anchor" href="#实战"></a> 实战</h1>
<p>这个实战爬取的是斗鱼上颜值主播（绿色健康）的相关信息，如封面、昵称</p>
<p>首先我们需要获取到能够爬取的URL，这里可以用Chrome自带的开发者工具切换到手机端获取</p>
<p><img src="https://i.loli.net/2020/07/04/bYiv5SIzEt71sGB.gif" alt="6" /></p>
<p>经查看可以发现，一个请求可以获取到8条内容</p>
<p><img src="https://i.loli.net/2020/07/04/ouw6cNFxgKfY3kd.png" alt="7" /></p>
<p>当然也可以通过抓包的方式获取手机端app的URL，这里不予演示，直接给出地址： <a target="_blank" rel="noopener" href="http://capi.douyucdn.cn/api/v1/getVerticalRoom?type=yz&amp;limit=20&amp;offset=">http://capi.douyucdn.cn/api/v1/getVerticalRoom?type=yz&amp;limit=20&amp;offset=</a></p>
<p>通过接口我们可以发现要爬取的字段名称是<code>nickname</code>和<code>ertical_src</code></p>
<p><img src="https://i.loli.net/2020/07/04/iSZNIEC1fRd6Q4o.png" alt="8" /></p>
<p>所以要去修改<code>items.py</code>，以得到我们想要的字段</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DouyuItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># 主播昵称</span></span><br><span class="line">    nickname = scrapy.Field()</span><br><span class="line">    <span class="comment"># 封面图片</span></span><br><span class="line">    vertical_src = scrapy.Field()</span><br></pre></td></tr></table></figure>
<p>接下来就是新建一个爬虫文件，取名为<code>douyu_yz</code>，并修改相关内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> douyu.items <span class="keyword">import</span> DouyuItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DouyuYzSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;douyu_yz&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;douyu.com&#x27;</span>]</span><br><span class="line">    base_url = <span class="string">&#x27;http://capi.douyucdn.cn/api/v1/getVerticalRoom?type=yz&amp;limit=20&amp;offset=&#x27;</span></span><br><span class="line">    offset = <span class="number">0</span></span><br><span class="line">    start_urls = [base_url + <span class="built_in">str</span>(offset)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="comment"># 提取数据，这里获取到的数据是json格式，可以直接转换数据类型</span></span><br><span class="line">        data_list = json.loads(response.body)[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(data_list) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_list:</span><br><span class="line">            item = DouyuItem()</span><br><span class="line">            item[<span class="string">&#x27;nickname&#x27;</span>] = data[<span class="string">&#x27;nickname&#x27;</span>].encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">            item[<span class="string">&#x27;vertical_src&#x27;</span>] = data[<span class="string">&#x27;vertical_src&#x27;</span>]</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line">            </span><br><span class="line">        self.offset += <span class="number">20</span></span><br><span class="line">        url = self.base_url + <span class="built_in">str</span>(self.offset)</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url, callback=self.parse, dont_filter=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><em>注：这里由于要爬取的信息比较多，所以以变量的方式把URL存成集合，并使用<code>yield</code>关键字回传数据</em></p>
<p>再接着就是编写管道文件了，需要获取到图片文件并进行解码和重命名</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DouyuPipeline</span>(<span class="params">ImagesPipeline</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span>(<span class="params">self, item, info</span>):</span></span><br><span class="line">        image_link = item[<span class="string">&#x27;vertical_src&#x27;</span>]</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(image_link)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span>(<span class="params">self, results, item, info</span>):</span></span><br><span class="line">        path = <span class="string">&#x27;/Users/JVxie/Desktop/douyu_yz/&#x27;</span></span><br><span class="line">        <span class="keyword">if</span> results[<span class="number">0</span>][<span class="number">0</span>]:</span><br><span class="line">            os.rename(path + results[<span class="number">0</span>][<span class="number">1</span>][<span class="string">&#x27;path&#x27;</span>], path + <span class="built_in">str</span>((item[<span class="string">&#x27;nickname&#x27;</span>]).decode() + <span class="string">&quot;.jpg&quot;</span>))</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>到这里，一个基本的爬虫项目已经完成，最后就是在<code>settings.py</code>中增加（修改）我们需要的配置</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置图片文件路径</span></span><br><span class="line">IMAGES_STORE = <span class="string">&#x27;/Users/JVxie/Desktop/douyu_yz&#x27;</span></span><br><span class="line"><span class="comment"># 开启管道</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;douyu.pipelines.DouyuPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 关闭robots协议</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>接下来执行<code>scrapy crawl douyu_yz</code>以进行爬取</p>
<p>可能会遇到的问题：</p>
<p><img src="https://i.loli.net/2020/07/04/fdXg5ikFN3CKL1q.png" alt="9" /></p>
<p>这是由于没有安装<code>pillow</code>库，使用<code>pip</code>安装即可</p>
<p>爬虫执行完成后在自定的目录中就能看到这些主播的封面图片了</p>
<p><img src="https://i.loli.net/2020/07/04/a2s3pC59g1KPzRH.png" alt="10" /></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Jeson Vendetta Xie</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://jvxie.com/spider-learning/">http://jvxie.com/spider-learning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://jvxie.com" target="_blank">JVxie's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/%E6%8A%80%E6%9C%AF/">技术</a><a class="post-meta__tags" href="/tags/Python/">Python</a><a class="post-meta__tags" href="/tags/Scrapy/">Scrapy</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/07/04/sRLU9dIAPOBKM5u.png" data-sites="facebook,twitter,google,weibo,wechat,qq,qzone"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button button--animated"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.png" target="_blank"><img class="post-qr-code-img" src="/img/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.png" target="_blank"><img class="post-qr-code-img" src="/img/alipay.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/algorithm-segtree/"><img class="prev-cover" src="https://pic.rmb.bdstatic.com/bjh/cfde8718407f5f3bc0e2a652e50705ff.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">[算法] 浅讲线段树和树状数组（一）</div></div></a></div><div class="next-post pull-right"><a href="/Java-Swing-learning/"><img class="next-cover" src="https://ae01.alicdn.com/kf/H547144fd2ff74915a5fd9043c70c2be3w.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Java Swing组件学习笔记</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/Java-Swing-learning/" title="Java Swing组件学习笔记"><img class="cover" src="https://ae01.alicdn.com/kf/H547144fd2ff74915a5fd9043c70c2be3w.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-11-27</div><div class="title">Java Swing组件学习笔记</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Waline</span><span class="switch-btn"></span><span class="second-comment">Valine</span></div></div><div class="comment-wrap"><div><div id="waline-wrap"></div></div><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/jvxie.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Jeson Vendetta Xie</div><div class="author-info__description">Talk is cheap, show me the code.</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">9</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">12</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="mailto:i@jvxie.com" target="_blank" title=""><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://github.com/JVxie" target="_blank" title=""><i class="fab fa-github"></i></a><a class="social-icon" href="https://weibo.com/jvxie111" target="_blank" title=""><i class="fab fa-weibo"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title=""><i class="fas fa-rss"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="toc-number">1.</span> <span class="toc-text"> 写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFscrapy"><span class="toc-number">2.</span> <span class="toc-text"> 什么是Scrapy</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AE%89%E8%A3%85"><span class="toc-number">3.</span> <span class="toc-text"> 如何安装</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8"><span class="toc-number">4.</span> <span class="toc-text"> 开始使用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE"><span class="toc-number">4.1.</span> <span class="toc-text"> 创建项目</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AA%E7%88%AC%E8%99%AB"><span class="toc-number">4.2.</span> <span class="toc-text"> 创建一个爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%90%E8%A1%8C%E7%88%AC%E8%99%AB"><span class="toc-number">4.3.</span> <span class="toc-text"> 运行爬虫</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E6%88%98"><span class="toc-number">5.</span> <span class="toc-text"> 实战</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/algorithm-segtree/" title="[算法] 浅讲线段树和树状数组（一）"><img src="https://pic.rmb.bdstatic.com/bjh/cfde8718407f5f3bc0e2a652e50705ff.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="[算法] 浅讲线段树和树状数组（一）"/></a><div class="content"><a class="title" href="/algorithm-segtree/" title="[算法] 浅讲线段树和树状数组（一）">[算法] 浅讲线段树和树状数组（一）</a><time datetime="2020-07-04T08:50:13.000Z" title="发表于 2020-07-04 16:50:13">2020-07-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/spider-learning/" title="Python爬虫学习笔记（一）Scrapy框架实战"><img src="https://i.loli.net/2020/07/04/sRLU9dIAPOBKM5u.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Python爬虫学习笔记（一）Scrapy框架实战"/></a><div class="content"><a class="title" href="/spider-learning/" title="Python爬虫学习笔记（一）Scrapy框架实战">Python爬虫学习笔记（一）Scrapy框架实战</a><time datetime="2020-07-03T10:20:57.000Z" title="发表于 2020-07-03 18:20:57">2020-07-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Java-Swing-learning/" title="Java Swing组件学习笔记"><img src="https://ae01.alicdn.com/kf/H547144fd2ff74915a5fd9043c70c2be3w.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Java Swing组件学习笔记"/></a><div class="content"><a class="title" href="/Java-Swing-learning/" title="Java Swing组件学习笔记">Java Swing组件学习笔记</a><time datetime="2019-11-27T07:30:29.000Z" title="发表于 2019-11-27 15:30:29">2019-11-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/algorithm-mobius/" title="[算法] 浅谈莫比乌斯反演"><img src="https://ae01.alicdn.com/kf/Hca3693487f744ad4b0a75856e314aa76K.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="[算法] 浅谈莫比乌斯反演"/></a><div class="content"><a class="title" href="/algorithm-mobius/" title="[算法] 浅谈莫比乌斯反演">[算法] 浅谈莫比乌斯反演</a><time datetime="2019-09-05T09:40:42.000Z" title="发表于 2019-09-05 17:40:42">2019-09-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/solution-brainstorming/" title="[题解] 头脑风暴专题"><img src="https://ae01.alicdn.com/kf/Hee2a7a6730c54787a8a6184a57d7ff44s.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="[题解] 头脑风暴专题"/></a><div class="content"><a class="title" href="/solution-brainstorming/" title="[题解] 头脑风暴专题">[题解] 头脑风暴专题</a><time datetime="2019-08-28T06:58:04.000Z" title="发表于 2019-08-28 14:58:04">2019-08-28</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By Jeson Vendetta Xie</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><a href="http://www.beian.miit.gov.cn/" target="_blank" rel="noopener"><img class="icp-icon entered loading" src="/img/icp.png" data-ll-status="loading"><span>闽ICP备16020881号-2</span></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>function loadWaline () {
  function initWaline () {
    let initData = {
      el: '#waline-wrap',
      serverURL: 'https://jvxie-waline-api.vercel.app',
      avatar: 'robohash',
      path: location.pathname,
      emojiCDN: '',
      emojiMaps: "",
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    const waline = new Waline(initData)
  }

  if (typeof Waline === 'function') initWaline() 
  else getScript('https://cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js').then(initWaline)
}

if ('Waline' === 'Waline' || !false) {
  if (false) btf.loadComment(document.getElementById('waline-wrap'),loadWaline)
  else setTimeout(loadWaline, 0)
} else {
  function loadOtherComment () {
    loadWaline()
  }
}</script><script>function loadValine () {
  function initValine () {
    let initData = {
      el: '#vcomment',
      appId: 'Fi2L1BRDMHFjLgV2rfPDPnYw-gzGzoHsz',
      appKey: 'UpdA3fdxMEswTW52A79QFrFh',
      placeholder: '来都来了，不说点什么吗？',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: true,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }
    
    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Waline' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="true"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>